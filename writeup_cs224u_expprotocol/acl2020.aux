\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{mccoy2019right,glockner2018breaking}
\citation{nie2019adversarial}
\citation{nie2019adversarial}
\citation{bowman2015large}
\citation{williams2017broad}
\newlabel{sec:hypothesis}{{1}{1}{Hypothesis}{section.1}{}}
\newlabel{sec:data}{{2}{1}{Data}{section.2}{}}
\newlabel{subsec:testset}{{2.1}{1}{Test Set}{subsection.2.1}{}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{table:labeldistribution}{{1}{2}{Distribution of labels across different datasets\relax }{table.caption.1}{}}
\newlabel{subsec:devset}{{2.2}{2}{Dev Set}{subsection.2.2}{}}
\newlabel{subsec:trainset}{{2.3}{2}{Train Set}{subsection.2.3}{}}
\newlabel{fig:attentionheads}{{1}{2}{Accuracy as a function of attention heads. BERT\textsubscript {BASE} model trained on MNLI only.\relax }{figure.caption.4}{}}
\newlabel{sec:metrics}{{3}{2}{Metrics}{section.3}{}}
\newlabel{table:accuracy}{{2}{3}{Evaluation results on the Dev/Test sets\relax }{table.caption.2}{}}
\newlabel{table:predictedlabeldistribution}{{3}{3}{Distribution of predicted labels on ANLI-A1. Models trained on MNLI only.\relax }{table.caption.3}{}}
\newlabel{sec:models}{{4}{3}{Models}{section.4}{}}
\newlabel{sec:reasoning}{{5}{3}{General Reasoning}{section.5}{}}
\newlabel{sec:progress}{{6}{3}{Progress Summary}{section.6}{}}
\newlabel{subsec:trainmnli}{{6.1}{3}{Training on MNLI only}{subsection.6.1}{}}
\newlabel{subsec:analyzetransformeradversarial}{{6.2}{3}{Analyzing Transformer models on Adversarial data}{subsection.6.2}{}}
\newlabel{table:erroranalysis}{{4}{4}{Examples where \textit {both} BERT\textsubscript {BASE} and RoBERTa\textsubscript {BASE} are wrong, while being in perfect agreement with each other. Models trained on MNLI only.\relax }{table.caption.5}{}}
\citation{michel2019sixteen}
\bibdata{acl2020}
\bibcite{bowman2015large}{{1}{2015}{{Bowman et~al.}}{{Bowman, Angeli, Potts, and Manning}}}
\bibcite{glockner2018breaking}{{2}{2018}{{Glockner et~al.}}{{Glockner, Shwartz, and Goldberg}}}
\bibcite{mccoy2019right}{{3}{2019}{{McCoy et~al.}}{{McCoy, Pavlick, and Linzen}}}
\bibcite{michel2019sixteen}{{4}{2019}{{Michel et~al.}}{{Michel, Levy, and Neubig}}}
\bibcite{nie2019adversarial}{{5}{2019}{{Nie et~al.}}{{Nie, Williams, Dinan, Bansal, Weston, and Kiela}}}
\bibcite{williams2017broad}{{6}{2017}{{Williams et~al.}}{{Williams, Nangia, and Bowman}}}
\bibstyle{acl_natbib}
\newlabel{subsec:trainmultiple}{{6.3}{5}{Training on multiple data sources}{subsection.6.3}{}}
