\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{mccoy2019right,glockner2018breaking}
\citation{nie2019adversarial}
\citation{nie2019adversarial}
\citation{bowman2015large}
\citation{williams2017broad}
\newlabel{sec:hypothesis}{{1}{1}{Hypothesis}{section.1}{}}
\newlabel{sec:data}{{2}{1}{Data}{section.2}{}}
\newlabel{subsec:testset}{{2.1}{1}{Test Set}{subsection.2.1}{}}
\citation{N18-1101}
\citation{dolan-brockett-2005-automatically}
\citation{WinNT}
\citation{cer-etal-2017-semeval}
\citation{rajpurkar-etal-2018-know}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{table:labeldistribution}{{1}{2}{Distribution of labels across different datasets\relax }{table.caption.1}{}}
\newlabel{subsec:devset}{{2.2}{2}{Dev Set}{subsection.2.2}{}}
\newlabel{subsec:trainset}{{2.3}{2}{Train Set}{subsection.2.3}{}}
\citation{dagan2005pascal}
\citation{bar2006second}
\citation{giampiccolo2007third}
\citation{bentivogli2009fifth}
\citation{levesque2012winograd}
\citation{pennington2014glove}
\citation{devlin-etal-2019-bert}
\citation{liu2019roberta}
\newlabel{sec:metrics}{{3}{3}{Metrics}{section.3}{}}
\newlabel{sec:models}{{4}{3}{Models}{section.4}{}}
\newlabel{subsec:randommodel}{{4.1}{3}{Random}{subsection.4.1}{}}
\newlabel{fig:attentionheads}{{1}{3}{Accuracy as a function of attention heads. BERT\textsubscript {BASE} model trained on MNLI only.\relax }{figure.caption.4}{}}
\newlabel{subsec:baselinemodel}{{4.2}{3}{Baseline}{subsection.4.2}{}}
\newlabel{subsec:bertmodel}{{4.3}{3}{BERT}{subsection.4.3}{}}
\newlabel{subsec:robertamodel}{{4.4}{3}{RoBERTa}{subsection.4.4}{}}
\newlabel{sec:reasoning}{{5}{3}{General Reasoning}{section.5}{}}
\newlabel{table:accuracy}{{2}{4}{Evaluation results on the Dev/Test sets\relax }{table.caption.2}{}}
\newlabel{fig:inoculation}{{2}{4}{Inoculation by fine-tuning on the test set\relax }{figure.caption.6}{}}
\citation{michel2019sixteen}
\newlabel{table:predictedlabeldistribution}{{3}{5}{Distribution of predicted labels on ANLI-A1. Models trained on MNLI only.\relax }{table.caption.3}{}}
\newlabel{sec:progress}{{6}{5}{Progress Summary}{section.6}{}}
\newlabel{subsec:trainmnli}{{6.1}{5}{Training on MNLI only}{subsection.6.1}{}}
\newlabel{subsec:analyzetransformeradversarial}{{6.2}{5}{Analyzing Transformer models on Adversarial data}{subsection.6.2}{}}
\newlabel{table:erroranalysis}{{4}{6}{Examples where \textit {both} BERT\textsubscript {BASE} and RoBERTa\textsubscript {BASE} are wrong, while being in perfect agreement with each other. Models trained on MNLI only.\relax }{table.caption.5}{}}
\bibdata{acl2020}
\bibcite{bar2006second}{{1}{2006}{{Bar-Haim et~al.}}{{Bar-Haim, Dagan, Dolan, Ferro, Giampiccolo, Magnini, and Szpektor}}}
\bibcite{bentivogli2009fifth}{{2}{2009}{{Bentivogli et~al.}}{{Bentivogli, Clark, Dagan, and Giampiccolo}}}
\bibcite{bowman2015large}{{3}{2015}{{Bowman et~al.}}{{Bowman, Angeli, Potts, and Manning}}}
\bibcite{cer-etal-2017-semeval}{{4}{2017}{{Cer et~al.}}{{Cer, Diab, Agirre, Lopez-Gazpio, and Specia}}}
\bibcite{dagan2005pascal}{{5}{2005}{{Dagan et~al.}}{{Dagan, Glickman, and Magnini}}}
\bibcite{devlin-etal-2019-bert}{{6}{2019}{{Devlin et~al.}}{{Devlin, Chang, Lee, and Toutanova}}}
\bibcite{dolan-brockett-2005-automatically}{{7}{2005}{{Dolan and Brockett}}{{}}}
\bibcite{giampiccolo2007third}{{8}{2007}{{Giampiccolo et~al.}}{{Giampiccolo, Magnini, Dagan, and Dolan}}}
\bibcite{glockner2018breaking}{{9}{2018}{{Glockner et~al.}}{{Glockner, Shwartz, and Goldberg}}}
\bibcite{WinNT}{{10}{2017}{{Iyer et~al.}}{{Iyer, Dandekar, and Csernai}}}
\bibcite{levesque2012winograd}{{11}{2012}{{Levesque et~al.}}{{Levesque, Davis, and Morgenstern}}}
\bibcite{liu2019roberta}{{12}{2019}{{Liu et~al.}}{{Liu, Ott, Goyal, Du, Joshi, Chen, Levy, Lewis, Zettlemoyer, and Stoyanov}}}
\newlabel{subsec:trainmultiple}{{6.3}{7}{Training on multiple data sources}{subsection.6.3}{}}
\newlabel{subsec:advice}{{6.4}{7}{Advice}{subsection.6.4}{}}
\bibcite{mccoy2019right}{{13}{2019}{{McCoy et~al.}}{{McCoy, Pavlick, and Linzen}}}
\bibcite{michel2019sixteen}{{14}{2019}{{Michel et~al.}}{{Michel, Levy, and Neubig}}}
\bibcite{nie2019adversarial}{{15}{2019}{{Nie et~al.}}{{Nie, Williams, Dinan, Bansal, Weston, and Kiela}}}
\bibcite{pennington2014glove}{{16}{2014}{{Pennington et~al.}}{{Pennington, Socher, and Manning}}}
\bibcite{rajpurkar-etal-2018-know}{{17}{2018}{{Rajpurkar et~al.}}{{Rajpurkar, Jia, and Liang}}}
\bibcite{N18-1101}{{18}{2018}{{Williams et~al.}}{{Williams, Nangia, and Bowman}}}
\bibcite{williams2017broad}{{19}{2017}{{Williams et~al.}}{{Williams, Nangia, and Bowman}}}
\bibstyle{acl_natbib}
